{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aabb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: pyarrow in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (22.0.0)\n",
      "Requirement already satisfied: shapely in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: pyproj in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (3.7.2)\n",
      "Requirement already satisfied: rtree in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: pandas in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: openpyxl in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: jupyterlab in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (4.4.10)\n",
      "Requirement already satisfied: seaborn in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (6.5.0)\n",
      "Requirement already satisfied: scipy in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pulp in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (3.3.0)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: certifi in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from pyproj) (2025.11.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (7.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (5.9.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (80.9.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (6.5.2)\n",
      "Requirement already satisfied: traitlets in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.23.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from plotly) (2.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (9.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (7.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.29.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.5.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "!pip install geopandas pyarrow shapely pyproj rtree matplotlib pandas numpy openpyxl jupyterlab seaborn plotly scipy scikit-learn pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87627e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mak/Documents/Optimization/Project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root (two levels up)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "print(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12d7c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.ipynb\n",
      "/home/mak/Documents/Optimization/Project/src/notebooks\n"
     ]
    }
   ],
   "source": [
    "!ls && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e52eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(\"/home/mak/Documents/Optimization/Project/data/processed/master_weekly_table.csv\")\n",
    "wm = wm[(wm[\"year\"] >= 2017) & (wm[\"year\"] <= 2024)].copy()\n",
    "wm.to_csv(\"/home/mak/Documents/Optimization/Project/data/processed/master_weekly_table_2017_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb04aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9c8c048",
   "metadata": {},
   "source": [
    "# 1ï¸âƒ£ Make labor realistic (seasonal, not 5M hours every week)\n",
    "Right now, after you build weekly_master, every row has the same labor_hours â‰ˆ 5,057,910.\n",
    "Weâ€™ll keep that as the annual pool, but scale it by week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume weekly_master is already built and contains `year`, `week`, `labor_hours`\n",
    "# wm = weekly_master.copy()\n",
    "\n",
    "# (Optional) keep original labor for reference\n",
    "wm[\"labor_hours_base\"] = wm[\"labor_hours\"]\n",
    "\n",
    "def labor_season_factor(week: int) -> float:\n",
    "    \"\"\"\n",
    "    Fraction of the annual labor pool effectively available in a given week.\n",
    "    Tune these numbers as you like.\n",
    "    \"\"\"\n",
    "    # Peak field activity during planting\n",
    "    if 16 <= week <= 20:\n",
    "        return 0.30      # 30% of annual workforce active in field\n",
    "\n",
    "    # Peak field activity during harvest\n",
    "    elif 36 <= week <= 45:\n",
    "        return 0.40      # 40% of annual workforce\n",
    "\n",
    "    # Shoulder / off-season\n",
    "    else:\n",
    "        return 0.10      # 10% in field operations\n",
    "\n",
    "# Apply seasonal factor\n",
    "wm[\"labor_hours\"] = wm.apply(\n",
    "    lambda r: r[\"labor_hours_base\"] * labor_season_factor(int(r[\"week\"])),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Overwrite weekly_master and resave\n",
    "weekly_master = wm\n",
    "weekly_master.to_csv(\"/home/mak/Documents/Optimization/Project/data/processed/master_weekly_table.csv\", index=False)\n",
    "\n",
    "weekly_master.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fd44df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ðŸš€ 4. Next step â€” build the Gurobi MILP model\\n    If youâ€™re ready to proceed, we will build:\\n    âœ” Decision variables\\n    Plant[f, w], Harvest[f, w]\\n\\n    âœ” Constraints\\n    Each field planted exactly once\\n    Each field harvested exactly once\\n    Plant only in planting window\\n    Harvest only in harvest window\\n    Machine capacity constraints using capacity_factor\\n    Labor constraints using labor_hours\\n    Harvest after plant\\n\\n    âœ” Objective options\\n    Minimize total completion week\\n    Minimize weighted lateness\\n    Minimize total duration\\n    Maximize operational efficiency\\n\\n    Weâ€™ll implement it cleanly in:\\n\\n    src/optimization/milp_scheduler.py_summary_\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ðŸš€ 4. Next step â€” build the Gurobi MILP model\n",
    "    If youâ€™re ready to proceed, we will build:\n",
    "    âœ” Decision variables\n",
    "    Plant[f, w], Harvest[f, w]\n",
    "\n",
    "    âœ” Constraints\n",
    "    Each field planted exactly once\n",
    "    Each field harvested exactly once\n",
    "    Plant only in planting window\n",
    "    Harvest only in harvest window\n",
    "    Machine capacity constraints using capacity_factor\n",
    "    Labor constraints using labor_hours\n",
    "    Harvest after plant\n",
    "\n",
    "    âœ” Objective options\n",
    "    Minimize total completion week\n",
    "    Minimize weighted lateness\n",
    "    Minimize total duration\n",
    "    Maximize operational efficiency\n",
    "\n",
    "    Weâ€™ll implement it cleanly in:\n",
    "\n",
    "    src/optimization/milp_scheduler.py_summary_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "339ee42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.ipynb\n",
      "/home/mak/Documents/Optimization/Project/src/notebooks\n"
     ]
    }
   ],
   "source": [
    "!ls && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4252fdff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Weekly master file not found: data/processed/master_weekly_table.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmilp_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_and_solve_schedule\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m schedule_2017 = \u001b[43mbuild_and_solve_schedule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/mak/Documents/Optimization/Project/data/processed/illinois_corn_fields_clean.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweekly_master_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed/master_weekly_table.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_year\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2017\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_planter_capacity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_harvester_capacity\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabor_plant_per_acre\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabor_harvest_per_acre\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_harvest_lag_weeks\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m schedule_2017\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/src/optimization/milp_scheduler.py:54\u001b[39m, in \u001b[36mbuild_and_solve_schedule\u001b[39m\u001b[34m(fields_path, weekly_master_path, target_year, base_planter_capacity, base_harvester_capacity, labor_plant_per_acre, labor_harvest_per_acre, min_harvest_lag_weeks, time_limit)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFields file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfields_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m weekly_master_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeekly master file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweekly_master_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m fields_df = pd.read_csv(fields_path)\n\u001b[32m     57\u001b[39m weekly_master = pd.read_csv(weekly_master_path)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Weekly master file not found: data/processed/master_weekly_table.csv"
     ]
    }
   ],
   "source": [
    "from src.optimization.milp_scheduler import build_and_solve_schedule\n",
    "\n",
    "schedule_2017 = build_and_solve_schedule(\n",
    "    fields_path=\"/home/mak/Documents/Optimization/Project/data/processed/illinois_corn_fields_clean.csv\",\n",
    "    weekly_master_path=\"data/processed/master_weekly_table.csv\",\n",
    "    target_year=2017,\n",
    "    base_planter_capacity=1000.0,\n",
    "    base_harvester_capacity=600.0,\n",
    "    labor_plant_per_acre=0.30,\n",
    "    labor_harvest_per_acre=0.40,\n",
    "    min_harvest_lag_weeks=6,\n",
    "    time_limit=60\n",
    ")\n",
    "\n",
    "schedule_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1acb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_2017.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8be2bf",
   "metadata": {},
   "source": [
    "3ï¸âƒ£ (Optional but nice) Make harvest capacity more weather-sensitive\n",
    "\n",
    "If you want harvest to match NASS even better, refine compute_harvest_weather_factor.\n",
    "\n",
    "ðŸ”§ Where\n",
    "\n",
    "In src/optimization/weather_capacity.py\n",
    "Find your existing compute_harvest_weather_factor and replace it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b07292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_harvest_weather_factor(row) -> float:\n",
    "    \"\"\"\n",
    "    Extra harvest penalty for bad drying conditions.\n",
    "\n",
    "    Uses:\n",
    "      - prcp_week_in : weekly rainfall (inches)\n",
    "      - TAVG         : avg temp (F)\n",
    "    \"\"\"\n",
    "    prcp = row.get(\"prcp_week_in\", 0.0) or 0.0\n",
    "    tavg = row.get(\"TAVG\", 60.0) or 60.0\n",
    "\n",
    "    # Start from 1.0 (no penalty)\n",
    "    factor = 1.0\n",
    "\n",
    "    # Heavy rain â†’ strong penalty\n",
    "    if prcp > 1.5:\n",
    "        factor *= 0.4\n",
    "    elif prcp > 0.8:\n",
    "        factor *= 0.7\n",
    "    else:\n",
    "        factor *= 1.0\n",
    "\n",
    "    # Cool temps â†’ slower drying\n",
    "    if tavg < 40:\n",
    "        factor *= 0.6\n",
    "    elif tavg < 50:\n",
    "        factor *= 0.8\n",
    "\n",
    "    # Clamp to [0.2, 1.0]\n",
    "    return float(np.clip(factor, 0.2, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fields = pd.read_csv(\"data/processed/illinois_corn_fields_clean.csv\")\n",
    "sched = schedule_2017.merge(fields, on=\"field_id\", how=\"left\")\n",
    "sched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b35547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sched.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_csv(\"data/processed/master_weekly_table.csv\")\n",
    "wm_2017 = wm[wm[\"year\"] == 2017].copy()\n",
    "# Planting acres per week\n",
    "plant_by_week = (\n",
    "    sched.groupby(\"plant_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .rename(\"plant_acres\")\n",
    "    .reset_index()\n",
    ")\n",
    "# Harvest acres per week\n",
    "harvest_by_week = (\n",
    "    sched.groupby(\"harvest_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .rename(\"harvest_acres\")\n",
    "    .reset_index()\n",
    ")\n",
    "# Merge with master to compare against capacity\n",
    "weekly_view = (\n",
    "    wm_2017[[\"week\", \"capacity_factor\", \"labor_hours\"]]\n",
    "    .merge(plant_by_week, left_on=\"week\", right_on=\"plant_week\", how=\"left\")\n",
    "    .merge(harvest_by_week, left_on=\"week\", right_on=\"harvest_week\", how=\"left\")\n",
    ")\n",
    "\n",
    "weekly_view[\"plant_week\"] = weekly_view[\"plant_week\"].fillna(0).astype(int)\n",
    "weekly_view[\"harvest_week\"] = weekly_view[\"harvest_week\"].fillna(0).astype(int)\n",
    "\n",
    "weekly_view[\"plant_acres\"] = weekly_view[\"plant_acres\"].fillna(0)\n",
    "weekly_view[\"harvest_acres\"] = weekly_view[\"harvest_acres\"].fillna(0)\n",
    "weekly_view.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a66a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_planter_capacity = 1400.0\n",
    "base_harvester_capacity = 950.0\n",
    "\n",
    "weekly_view[\"plant_capacity\"] = (\n",
    "    base_planter_capacity * weekly_view[\"capacity_factor\"]\n",
    ")\n",
    "weekly_view[\"harvest_capacity\"] = (\n",
    "    base_harvester_capacity * weekly_view[\"capacity_factor\"]\n",
    ")\n",
    "\n",
    "weekly_view[\"plant_utilization\"] = (\n",
    "    weekly_view[\"plant_acres\"] / weekly_view[\"plant_capacity\"]\n",
    ")\n",
    "weekly_view[\"harvest_utilization\"] = (\n",
    "    weekly_view[\"harvest_acres\"] / weekly_view[\"harvest_capacity\"]\n",
    ")\n",
    "\n",
    "weekly_view[[\"week\", \"plant_acres\", \"plant_capacity\", \"plant_utilization\",\n",
    "             \"harvest_acres\", \"harvest_capacity\", \"harvest_utilization\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_2017.to_csv(\"data/processed/schedule_2017.csv\", index=False)\n",
    "schedule_2017.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load schedule\n",
    "# If you saved it elsewhere, change the path accordingly\n",
    "schedule_2017 = pd.read_csv(\"data/processed/schedule_2017.csv\")\n",
    "\n",
    "# 2. Sort by planting week so the chart looks orderly\n",
    "schedule_2017 = schedule_2017.sort_values(\"plant_week\").reset_index(drop=True)\n",
    "\n",
    "# (Optional) Limit number of fields shown, so the plot stays readable\n",
    "max_fields = 30   # change or remove this to plot all fields\n",
    "plot_df = schedule_2017.head(max_fields).copy()\n",
    "\n",
    "# Duration of each field's growing season\n",
    "plot_df[\"duration\"] = plot_df[\"harvest_week\"] - plot_df[\"plant_week\"]\n",
    "\n",
    "# 3. Build colored Gantt chart\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "y_positions = list(range(len(plot_df)))\n",
    "\n",
    "# Growing season bar (plant â†’ harvest)\n",
    "ax.barh(\n",
    "    y_positions,\n",
    "    plot_df[\"duration\"],\n",
    "    left=plot_df[\"plant_week\"],\n",
    "    color=\"lightgreen\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    "    label=\"Plant â†’ Harvest\"\n",
    ")\n",
    "\n",
    "# Mark planting week (green triangle)\n",
    "ax.scatter(\n",
    "    plot_df[\"plant_week\"],\n",
    "    y_positions,\n",
    "    color=\"green\",\n",
    "    marker=\">\",\n",
    "    s=60,\n",
    "    label=\"Planting week\"\n",
    ")\n",
    "\n",
    "# Mark harvest week (orange square)\n",
    "ax.scatter(\n",
    "    plot_df[\"harvest_week\"],\n",
    "    y_positions,\n",
    "    color=\"orange\",\n",
    "    marker=\"s\",\n",
    "    s=60,\n",
    "    label=\"Harvest week\"\n",
    ")\n",
    "\n",
    "# 4. Labeling & styling\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(plot_df[\"field_id\"])\n",
    "ax.set_xlabel(\"Week of Year\")\n",
    "ax.set_title(\"Corn Planting & Harvest Gantt â€“ 2017\")\n",
    "ax.invert_yaxis()  # first field at top\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ce18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------\n",
    "# Load datasets\n",
    "# ------------------------\n",
    "\n",
    "# NASS planting (cleaned)\n",
    "plant_nass_path = \"data/processed/nass_corn_planting_weekly_clean.csv\"\n",
    "plant_nass = pd.read_csv(plant_nass_path)\n",
    "\n",
    "# NASS harvest (cleaned)\n",
    "harvest_nass_path = \"data/processed/nass_corn_harvest_weekly_clean.csv\"\n",
    "harvest_nass = pd.read_csv(harvest_nass_path)\n",
    "\n",
    "# MILP optimized schedule for 2017\n",
    "sched = pd.read_csv(\"data/processed/schedule_2017.csv\")\n",
    "\n",
    "# ------------------------\n",
    "# Filter NASS for 2017\n",
    "# ------------------------\n",
    "plant_nass_2017 = plant_nass[plant_nass[\"Year\"] == 2017].copy()\n",
    "harvest_nass_2017 = harvest_nass[harvest_nass[\"Year\"] == 2017].copy()\n",
    "\n",
    "# Rename for easier use\n",
    "plant_nass_2017 = plant_nass_2017[[\"week\", \"pct_planted\"]].sort_values(\"week\")\n",
    "harvest_nass_2017 = harvest_nass_2017[[\"week\", \"pct_harvested\"]].sort_values(\"week\")\n",
    "\n",
    "# ------------------------\n",
    "# Build Optimized Curves\n",
    "# ------------------------\n",
    "\n",
    "# Insert field acres\n",
    "fields = pd.read_csv(\"data/processed/illinois_corn_fields_clean.csv\")\n",
    "sched = sched.merge(fields[[\"field_id\", \"acres\"]], on=\"field_id\", how=\"left\")\n",
    "\n",
    "total_acres = sched[\"acres\"].sum()\n",
    "\n",
    "# MILP planting curve (%)\n",
    "plant_curve_opt = (\n",
    "    sched.groupby(\"plant_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .cumsum() / total_acres * 100\n",
    ")\n",
    "\n",
    "# MILP harvest curve (%)\n",
    "harvest_curve_opt = (\n",
    "    sched.groupby(\"harvest_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .cumsum() / total_acres * 100\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# Plot Comparison\n",
    "# ------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Planting\n",
    "plt.plot(plant_nass_2017[\"week\"], plant_nass_2017[\"pct_planted\"],\n",
    "         label=\"NASS Actual Planting (2017)\", marker=\"o\", color=\"green\")\n",
    "plt.plot(plant_curve_opt.index, plant_curve_opt.values,\n",
    "         label=\"Optimized Planting (MILP)\", marker=\"o\", linestyle=\"--\", color=\"darkgreen\")\n",
    "\n",
    "# Harvest\n",
    "plt.plot(harvest_nass_2017[\"week\"], harvest_nass_2017[\"pct_harvested\"],\n",
    "         label=\"NASS Actual Harvest (2017)\", marker=\"s\", color=\"orange\")\n",
    "plt.plot(harvest_curve_opt.index, harvest_curve_opt.values,\n",
    "         label=\"Optimized Harvest (MILP)\", marker=\"s\", linestyle=\"--\", color=\"darkorange\")\n",
    "\n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Percent Complete (%)\")\n",
    "plt.title(\"Corn Planting & Harvest: NASS 2017 vs MILP Optimized\")\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114ac11",
   "metadata": {},
   "source": [
    "# MILP V2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.milp_schedulerv2 import build_and_solve_schedule_v2\n",
    "\n",
    "schedule_2017_v2 = build_and_solve_schedule_v2(\n",
    "    fields_path=\"data/processed/illinois_corn_fields_clean.csv\",\n",
    "    weekly_master_path=\"data/processed/master_weekly_table.csv\",\n",
    "    target_year=2017,\n",
    "    base_planter_capacity=1000.0,\n",
    "    base_harvester_capacity=750.0,\n",
    "    labor_plant_per_acre=0.15,\n",
    "    labor_harvest_per_acre=0.20,\n",
    "    min_harvest_lag_weeks=6,\n",
    "    phys_maturity_lag_weeks=16,\n",
    "    late_buffer_weeks=3,\n",
    "    early_penalty_weight=10.0,\n",
    "    late_penalty_weight=5.0,\n",
    "    time_limit=60,\n",
    ")\n",
    "\n",
    "schedule_2017_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b12716",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_2017_v2.to_csv(\"data/processed/schedule_2017_v2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_year = 2017\n",
    "\n",
    "# ---------- PATHS ----------\n",
    "schedule_path = \"data/processed/schedule_2017_v2.csv\"  # or schedule_2017.csv\n",
    "fields_path   = \"data/processed/illinois_corn_fields_clean.csv\"\n",
    "\n",
    "plant_nass_path   = \"data/processed/nass_corn_planting_weekly_clean.csv\"\n",
    "harvest_nass_path = \"data/processed/nass_corn_harvest_weekly_clean.csv\"\n",
    "\n",
    "# ---------- 1. LOAD DATA ----------\n",
    "\n",
    "# Schedule + fields (for acres)\n",
    "sched = pd.read_csv(schedule_path)\n",
    "fields = pd.read_csv(fields_path)\n",
    "\n",
    "sched = sched.merge(fields[[\"field_id\", \"acres\"]], on=\"field_id\", how=\"left\")\n",
    "total_acres = sched[\"acres\"].sum()\n",
    "\n",
    "# Clean NASS\n",
    "plant_nass   = pd.read_csv(plant_nass_path)\n",
    "harvest_nass = pd.read_csv(harvest_nass_path)\n",
    "\n",
    "plant_nass_yr   = plant_nass[plant_nass[\"Year\"] == target_year].copy()\n",
    "harvest_nass_yr = harvest_nass[harvest_nass[\"Year\"] == target_year].copy()\n",
    "\n",
    "# ---------- 2. BUILD CURVES (ACTUAL vs OPTIMIZED) ----------\n",
    "\n",
    "# Weeks universe (1â€“52)\n",
    "weeks = pd.Index(range(1, 53), name=\"week\")\n",
    "\n",
    "# NASS planting curve (already %)\n",
    "plant_actual = (\n",
    "    plant_nass_yr.set_index(\"week\")[\"pct_planted\"]\n",
    "    .reindex(weeks)\n",
    "    .ffill()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# NASS harvest curve\n",
    "harvest_actual = (\n",
    "    harvest_nass_yr.set_index(\"week\")[\"pct_harvested\"]\n",
    "    .reindex(weeks)\n",
    "    .ffill()\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Optimized planting (% of total acres)\n",
    "plant_opt = (\n",
    "    sched.groupby(\"plant_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .cumsum() / total_acres * 100.0\n",
    ")\n",
    "plant_opt = plant_opt.reindex(weeks).ffill().fillna(0)\n",
    "\n",
    "# Optimized harvest (% of total acres)\n",
    "harvest_opt = (\n",
    "    sched.groupby(\"harvest_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .cumsum() / total_acres * 100.0\n",
    ")\n",
    "harvest_opt = harvest_opt.reindex(weeks).ffill().fillna(0)\n",
    "\n",
    "# Deviation (absolute)\n",
    "plant_diff   = (plant_opt   - plant_actual).abs()\n",
    "harvest_diff = (harvest_opt - harvest_actual).abs()\n",
    "\n",
    "# ---------- 3. PLOT: 2-ROW DEVIATION vs ACTUAL ----------\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# --- Row 1: Planting ---\n",
    "ax = axes[0]\n",
    "\n",
    "ax.plot(weeks, plant_actual, label=\"NASS Planting (Actual)\", color=\"green\", marker=\"o\")\n",
    "ax.plot(weeks, plant_opt,    label=\"Optimized Planting (MILP)\", color=\"darkgreen\",\n",
    "        linestyle=\"--\", marker=\"x\")\n",
    "\n",
    "# Shaded deviation area\n",
    "ax.fill_between(\n",
    "    weeks,\n",
    "    plant_actual,\n",
    "    plant_opt,\n",
    "    where=None,\n",
    "    alpha=0.25,\n",
    "    color=\"lightgreen\",\n",
    "    label=\"Planting deviation\"\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Percent Planted (%)\")\n",
    "ax.set_title(f\"Corn Planting vs Harvest {target_year}: NASS vs Optimized (Deviation)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# --- Row 2: Harvest ---\n",
    "ax = axes[1]\n",
    "\n",
    "ax.plot(weeks, harvest_actual, label=\"NASS Harvest (Actual)\", color=\"orange\", marker=\"s\")\n",
    "ax.plot(weeks, harvest_opt,    label=\"Optimized Harvest (MILP)\", color=\"darkorange\",\n",
    "        linestyle=\"--\", marker=\"d\")\n",
    "\n",
    "ax.fill_between(\n",
    "    weeks,\n",
    "    harvest_actual,\n",
    "    harvest_opt,\n",
    "    where=None,\n",
    "    alpha=0.25,\n",
    "    color=\"moccasin\",\n",
    "    label=\"Harvest deviation\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Week of Year\")\n",
    "ax.set_ylabel(\"Percent Harvested (%)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d5db9",
   "metadata": {},
   "source": [
    "# Regional Breakdown Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------\n",
    "# CONFIG\n",
    "# --------------------------\n",
    "target_year = 2017\n",
    "\n",
    "schedule_path = \"data/processed/schedule_2017_v2.csv\"  # or _2017.csv\n",
    "fields_path   = \"data/processed/illinois_corn_fields_clean.csv\"\n",
    "\n",
    "plant_nass_path   = \"data/processed/nass_corn_planting_weekly_clean.csv\"\n",
    "harvest_nass_path = \"data/processed/nass_corn_harvest_weekly_clean.csv\"\n",
    "\n",
    "regions = [\"North\", \"Central\", \"South\"]\n",
    "\n",
    "# --------------------------\n",
    "# LOAD DATA\n",
    "# --------------------------\n",
    "sched  = pd.read_csv(schedule_path)\n",
    "fields = pd.read_csv(fields_path)\n",
    "\n",
    "sched = sched.merge(fields[[\"field_id\", \"acres\", \"region\"]], on=\"field_id\", how=\"left\")\n",
    "\n",
    "# Clean NASS\n",
    "plant_nass   = pd.read_csv(plant_nass_path)\n",
    "harvest_nass = pd.read_csv(harvest_nass_path)\n",
    "\n",
    "plant_actual_yr   = plant_nass[plant_nass[\"Year\"] == target_year].copy()\n",
    "harvest_actual_yr = harvest_nass[harvest_nass[\"Year\"] == target_year].copy()\n",
    "\n",
    "# Weeks\n",
    "weeks = pd.Index(range(1, 53), name=\"week\")\n",
    "\n",
    "# --------------------------\n",
    "# Function: build NASS curve by region\n",
    "# --------------------------\n",
    "def build_nass_curve_by_region(nass_df, nass_col, region_name):\n",
    "    \"\"\"\n",
    "    NASS is statewide, not region-specific.\n",
    "    So each region gets the SAME NASS curve.\n",
    "    \"\"\"\n",
    "    region_curve = (\n",
    "        nass_df.set_index(\"week\")[nass_col]\n",
    "        .reindex(weeks)\n",
    "        .ffill()\n",
    "        .fillna(0)\n",
    "    )\n",
    "    return region_curve\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Function: build optimized curve by region\n",
    "# --------------------------\n",
    "def build_opt_curve(df, week_col, acres_col, region_name):\n",
    "    subset = df[df[\"region\"] == region_name]\n",
    "    \n",
    "    if subset.empty:\n",
    "        return pd.Series(0, index=weeks)\n",
    "\n",
    "    total_acres = subset[acres_col].sum()\n",
    "\n",
    "    curve = (\n",
    "        subset.groupby(week_col)[\"acres\"]\n",
    "        .sum()\n",
    "        .cumsum() / total_acres * 100\n",
    "    )\n",
    "    return curve.reindex(weeks).ffill().fillna(0)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# PLOTTING: 3-regions Ã— planting/harvest\n",
    "# --------------------------\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12), sharex=True)\n",
    "\n",
    "for i, region in enumerate(regions):\n",
    "\n",
    "    # ---------- Planting ----------\n",
    "    ax = axes[i, 0]\n",
    "\n",
    "    nass_curve = build_nass_curve_by_region(plant_actual_yr, \"pct_planted\", region)\n",
    "    opt_curve  = build_opt_curve(sched, \"plant_week\", \"acres\", region)\n",
    "\n",
    "    ax.plot(weeks, nass_curve, label=\"NASS Planting\", color=\"green\")\n",
    "    ax.plot(weeks, opt_curve, label=\"Optimized Planting\", color=\"darkgreen\", linestyle=\"--\")\n",
    "\n",
    "    ax.fill_between(weeks, nass_curve, opt_curve, alpha=0.2, color=\"lightgreen\")\n",
    "    ax.set_ylabel(f\"{region}\\nPlanted (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Planting: NASS vs Optimized (by Region)\")\n",
    "\n",
    "    # ---------- Harvest ----------\n",
    "    ax = axes[i, 1]\n",
    "\n",
    "    nass_curve_h = build_nass_curve_by_region(harvest_actual_yr, \"pct_harvested\", region)\n",
    "    opt_curve_h  = build_opt_curve(sched, \"harvest_week\", \"acres\", region)\n",
    "\n",
    "    ax.plot(weeks, nass_curve_h, label=\"NASS Harvest\", color=\"orange\")\n",
    "    ax.plot(weeks, opt_curve_h, label=\"Optimized Harvest\", color=\"darkorange\", linestyle=\"--\")\n",
    "\n",
    "    ax.fill_between(weeks, nass_curve_h, opt_curve_h, alpha=0.2, color=\"moccasin\")\n",
    "\n",
    "    ax.set_ylabel(f\"{region}\\nHarvested (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Harvest: NASS vs Optimized (by Region)\")\n",
    "\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"Week of Year\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea1588",
   "metadata": {},
   "source": [
    "â€œTo capture spatial heterogeneity, I broke the schedule down by region.\n",
    "North, Central, and South Illinois have different temperatures, moisture patterns, and operational constraints â€” so planting and harvest timing differs in practice.â€\n",
    "\n",
    "â€œThe optimized schedule responds to these differences:\n",
    "Southern fields plant and harvest slightly earlier, while northern fields are delayed, matching agronomic reality.â€\n",
    "\n",
    "â€œThis demonstrates that the MILP is not just mathematically correct â€” it reflects real-world spatial agronomic behavior.â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Config ---\n",
    "target_year = 2017\n",
    "\n",
    "schedule_path       = \"data/processed/schedule_2017_v2.csv\"  # or schedule_2017.csv\n",
    "fields_path         = \"data/processed/illinois_corn_fields_clean.csv\"\n",
    "weekly_master_path  = \"data/processed/master_weekly_table.csv\"\n",
    "\n",
    "base_planter_capacity   = 1400.0   # acres/week at capacity_factor=1\n",
    "base_harvester_capacity = 950.0    # acres/week at capacity_factor=1\n",
    "labor_plant_per_acre    = 0.15\n",
    "labor_harvest_per_acre  = 0.20\n",
    "\n",
    "# --- Load data ---\n",
    "sched = pd.read_csv(schedule_path)\n",
    "fields = pd.read_csv(fields_path)\n",
    "wm    = pd.read_csv(weekly_master_path)\n",
    "\n",
    "# Merge acres into schedule\n",
    "sched = sched.merge(fields[[\"field_id\", \"acres\"]], on=\"field_id\", how=\"left\")\n",
    "\n",
    "# Filter master to target year\n",
    "wm_year = wm[wm[\"year\"] == target_year].copy()\n",
    "wm_year = wm_year.sort_values(\"week\").reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# Plant & harvest acres per week\n",
    "# --------------------------\n",
    "plant_by_week = (\n",
    "    sched.groupby(\"plant_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .rename(\"plant_acres\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"plant_week\": \"week\"})\n",
    ")\n",
    "\n",
    "harvest_by_week = (\n",
    "    sched.groupby(\"harvest_week\")[\"acres\"]\n",
    "    .sum()\n",
    "    .rename(\"harvest_acres\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"harvest_week\": \"week\"})\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Build weekly_view\n",
    "# --------------------------\n",
    "weekly_view = (\n",
    "    wm_year[[\"week\", \"capacity_factor\", \"labor_hours\"]]\n",
    "    .merge(plant_by_week,  on=\"week\", how=\"left\")\n",
    "    .merge(harvest_by_week, on=\"week\", how=\"left\")\n",
    ")\n",
    "\n",
    "weekly_view[\"plant_acres\"]   = weekly_view[\"plant_acres\"].fillna(0.0)\n",
    "weekly_view[\"harvest_acres\"] = weekly_view[\"harvest_acres\"].fillna(0.0)\n",
    "\n",
    "# Capacity from equipment * weather factor\n",
    "weekly_view[\"plant_capacity\"] = base_planter_capacity   * weekly_view[\"capacity_factor\"]\n",
    "weekly_view[\"harvest_capacity\"] = base_harvester_capacity * weekly_view[\"capacity_factor\"]\n",
    "\n",
    "# Utilization (0â€“1)\n",
    "weekly_view[\"plant_utilization\"] = (\n",
    "    weekly_view[\"plant_acres\"] / weekly_view[\"plant_capacity\"].replace(0, pd.NA)\n",
    ").fillna(0.0)\n",
    "\n",
    "weekly_view[\"harvest_utilization\"] = (\n",
    "    weekly_view[\"harvest_acres\"] / weekly_view[\"harvest_capacity\"].replace(0, pd.NA)\n",
    ").fillna(0.0)\n",
    "\n",
    "# Labor demand & utilization\n",
    "weekly_view[\"labor_demand\"] = (\n",
    "    weekly_view[\"plant_acres\"]   * labor_plant_per_acre\n",
    "  + weekly_view[\"harvest_acres\"] * labor_harvest_per_acre\n",
    ")\n",
    "\n",
    "weekly_view[\"labor_utilization\"] = (\n",
    "    weekly_view[\"labor_demand\"] / weekly_view[\"labor_hours\"].replace(0, pd.NA)\n",
    ").fillna(0.0)\n",
    "\n",
    "weekly_view.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "weeks = weekly_view[\"week\"]\n",
    "\n",
    "# --- 1) Planter utilization ---\n",
    "ax = axes[0]\n",
    "ax.plot(weeks, weekly_view[\"plant_utilization\"] * 100, marker=\"o\", label=\"Planter utilization (%)\")\n",
    "ax.axhline(100, linestyle=\"--\", alpha=0.5)\n",
    "ax.set_ylabel(\"Planter Utilization (%)\")\n",
    "ax.set_title(f\"Weekly Utilization Dashboard â€“ {target_year}\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "# You can also overlay raw acres vs capacity if you want:\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(weeks, weekly_view[\"plant_acres\"], marker=\"x\", alpha=0.6, label=\"Plant acres\")\n",
    "ax2.plot(weeks, weekly_view[\"plant_capacity\"], linestyle=\"--\", alpha=0.6, label=\"Plant capacity (acres)\")\n",
    "ax2.set_ylabel(\"Plant Acres / Capacity\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "# --- 2) Harvester utilization ---\n",
    "ax = axes[1]\n",
    "ax.plot(weeks, weekly_view[\"harvest_utilization\"] * 100, marker=\"s\", label=\"Harvester utilization (%)\")\n",
    "ax.axhline(100, linestyle=\"--\", alpha=0.5)\n",
    "ax.set_ylabel(\"Harvester Utilization (%)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(weeks, weekly_view[\"harvest_acres\"], marker=\"x\", alpha=0.6, label=\"Harvest acres\")\n",
    "ax2.plot(weeks, weekly_view[\"harvest_capacity\"], linestyle=\"--\", alpha=0.6, label=\"Harvest capacity (acres)\")\n",
    "ax2.set_ylabel(\"Harvest Acres / Capacity\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "# --- 3) Labor utilization ---\n",
    "ax = axes[2]\n",
    "ax.plot(weeks, weekly_view[\"labor_utilization\"] * 100, marker=\"^\", label=\"Labor utilization (%)\")\n",
    "ax.axhline(100, linestyle=\"--\", alpha=0.5)\n",
    "ax.set_xlabel(\"Week of Year\")\n",
    "ax.set_ylabel(\"Labor Utilization (%)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(weeks, weekly_view[\"labor_demand\"], marker=\"x\", alpha=0.6, label=\"Labor demand (hours)\")\n",
    "ax2.plot(weeks, weekly_view[\"labor_hours\"], linestyle=\"--\", alpha=0.6, label=\"Labor available (hours)\")\n",
    "ax2.set_ylabel(\"Labor Hours\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If weekly_view already exists, skip this load\n",
    "# weekly_view = pd.read_csv(\"data/processed/weekly_view_2017.csv\")\n",
    "\n",
    "# --- KPIs ---\n",
    "def print_utilization_kpis(weekly_view, target_year):\n",
    "    def kpi(col_name, label):\n",
    "        max_u = weekly_view[col_name].max()\n",
    "        max_week = int(weekly_view.loc[weekly_view[col_name].idxmax(), \"week\"])\n",
    "        weeks_high = (weekly_view[col_name] >= 0.8).sum()\n",
    "        print(f\"{label}:\")\n",
    "        print(f\"  â€¢ Peak utilization = {max_u*100:.1f}% (week {max_week})\")\n",
    "        print(f\"  â€¢ Weeks â‰¥ 80% utilization = {weeks_high}\")\n",
    "        print()\n",
    "\n",
    "    print(f\"=== Utilization KPIs â€“ {target_year} ===\")\n",
    "    kpi(\"plant_utilization\",   \"Planter\")\n",
    "    kpi(\"harvest_utilization\", \"Harvester\")\n",
    "    kpi(\"labor_utilization\",   \"Labor\")\n",
    "\n",
    "# Example call\n",
    "print_utilization_kpis(weekly_view, target_year=2017)\n",
    "\n",
    "\n",
    "# --- Pretty dashboard ---\n",
    "def plot_weekly_utilization_dashboard(weekly_view, target_year=2017):\n",
    "    weeks = weekly_view[\"week\"]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    # Helper to add shading above 80%\n",
    "    def shade_high_util(ax, util_series):\n",
    "        ax.fill_between(\n",
    "            weeks,\n",
    "            80,\n",
    "            util_series * 100,\n",
    "            where=(util_series * 100 >= 80),\n",
    "            alpha=0.15,\n",
    "            step=None,\n",
    "        )\n",
    "\n",
    "    # 1) Planter\n",
    "    ax = axes[0]\n",
    "    ax.plot(weeks, weekly_view[\"plant_utilization\"] * 100, marker=\"o\",\n",
    "            label=\"Planter utilization (%)\")\n",
    "    ax.axhline(100, linestyle=\"--\")\n",
    "    shade_high_util(ax, weekly_view[\"plant_utilization\"])\n",
    "\n",
    "    ax.set_ylabel(\"Planter Utilization (%)\")\n",
    "    ax.set_title(f\"Weekly Utilization Dashboard â€“ {target_year}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(weeks, weekly_view[\"plant_acres\"], marker=\"x\", linestyle=\"-\",\n",
    "             alpha=0.6, label=\"Plant acres\")\n",
    "    ax2.plot(weeks, weekly_view[\"plant_capacity\"], linestyle=\"--\", alpha=0.6,\n",
    "             label=\"Plant capacity (acres)\")\n",
    "    ax2.set_ylabel(\"Plant Acres / Capacity\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    # 2) Harvester\n",
    "    ax = axes[1]\n",
    "    ax.plot(weeks, weekly_view[\"harvest_utilization\"] * 100, marker=\"s\",\n",
    "            label=\"Harvester utilization (%)\")\n",
    "    ax.axhline(100, linestyle=\"--\")\n",
    "    shade_high_util(ax, weekly_view[\"harvest_utilization\"])\n",
    "\n",
    "    ax.set_ylabel(\"Harvester Utilization (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(weeks, weekly_view[\"harvest_acres\"], marker=\"x\", linestyle=\"-\",\n",
    "             alpha=0.6, label=\"Harvest acres\")\n",
    "    ax2.plot(weeks, weekly_view[\"harvest_capacity\"], linestyle=\"--\", alpha=0.6,\n",
    "             label=\"Harvest capacity (acres)\")\n",
    "    ax2.set_ylabel(\"Harvest Acres / Capacity\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    # 3) Labor\n",
    "    ax = axes[2]\n",
    "    ax.plot(weeks, weekly_view[\"labor_utilization\"] * 100, marker=\"^\",\n",
    "            label=\"Labor utilization (%)\")\n",
    "    ax.axhline(100, linestyle=\"--\")\n",
    "    shade_high_util(ax, weekly_view[\"labor_utilization\"])\n",
    "\n",
    "    ax.set_xlabel(\"Week of Year\")\n",
    "    ax.set_ylabel(\"Labor Utilization (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(weeks, weekly_view[\"labor_demand\"], marker=\"x\", linestyle=\"-\",\n",
    "             alpha=0.6, label=\"Labor demand (hours)\")\n",
    "    ax2.plot(weeks, weekly_view[\"labor_hours\"], linestyle=\"--\", alpha=0.6,\n",
    "             label=\"Labor available (hours)\")\n",
    "    ax2.set_ylabel(\"Labor Hours\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example call\n",
    "plot_weekly_utilization_dashboard(weekly_view, target_year=2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53437f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_weekly_utilization_plotly(weekly_view, target_year=2017):\n",
    "    weeks = weekly_view[\"week\"]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=(\n",
    "            \"Planter Utilization & Capacity\",\n",
    "            \"Harvester Utilization & Capacity\",\n",
    "            \"Labor Utilization & Capacity\"\n",
    "        ),\n",
    "        specs=[[{\"secondary_y\": True}],\n",
    "               [{\"secondary_y\": True}],\n",
    "               [{\"secondary_y\": True}]]\n",
    "    )\n",
    "\n",
    "    # --- Row 1: Planter ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"plant_utilization\"] * 100,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Planter utilization (%)\",\n",
    "        ),\n",
    "        row=1, col=1, secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"plant_acres\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Plant acres\",\n",
    "        ),\n",
    "        row=1, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"plant_capacity\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Plant capacity (acres)\",\n",
    "            line=dict(dash=\"dash\"),\n",
    "        ),\n",
    "        row=1, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # --- Row 2: Harvester ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"harvest_utilization\"] * 100,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Harvester utilization (%)\",\n",
    "        ),\n",
    "        row=2, col=1, secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"harvest_acres\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Harvest acres\",\n",
    "        ),\n",
    "        row=2, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"harvest_capacity\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Harvest capacity (acres)\",\n",
    "            line=dict(dash=\"dash\"),\n",
    "        ),\n",
    "        row=2, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # --- Row 3: Labor ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"labor_utilization\"] * 100,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Labor utilization (%)\",\n",
    "        ),\n",
    "        row=3, col=1, secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"labor_demand\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Labor demand (hours)\",\n",
    "        ),\n",
    "        row=3, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=weeks,\n",
    "            y=weekly_view[\"labor_hours\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Labor available (hours)\",\n",
    "            line=dict(dash=\"dash\"),\n",
    "        ),\n",
    "        row=3, col=1, secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_yaxes(title_text=\"Planter Utilization (%)\", row=1, col=1, secondary_y=False, range=[0, 110])\n",
    "    fig.update_yaxes(title_text=\"Acres\", row=1, col=1, secondary_y=True)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Harvester Utilization (%)\", row=2, col=1, secondary_y=False, range=[0, 110])\n",
    "    fig.update_yaxes(title_text=\"Acres\", row=2, col=1, secondary_y=True)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Labor Utilization (%)\", row=3, col=1, secondary_y=False, range=[0, 110])\n",
    "    fig.update_yaxes(title_text=\"Labor Hours\", row=3, col=1, secondary_y=True)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Week of Year\", row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Weekly Utilization Dashboard (Interactive) â€“ {target_year}\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1, xanchor=\"center\", x=0.5),\n",
    "        height=900,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Example call\n",
    "plot_weekly_utilization_plotly(weekly_view, target_year=2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990efd1d",
   "metadata": {},
   "source": [
    "# Monte Carlo SImulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38cbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from src.optimization.milp_schedulerv2 import build_and_solve_schedule_v2\n",
    "\n",
    "MASTER_PATH = Path(\"data/processed/master_weekly_table.csv\")\n",
    "\n",
    "def sample_weather_year(noaa_weekly_all: pd.DataFrame, target_year: int, rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    Bootstrap: pick a random historical year and use its weekly weather for target_year.\n",
    "    noaa_weekly_all should have columns: ['year','week','prcp_week_in','TAVG','TMAX','TMIN','AWND',...]\n",
    "    \"\"\"\n",
    "    candidate_years = sorted(noaa_weekly_all[\"year\"].unique())\n",
    "    sampled_year = int(rng.choice(candidate_years))\n",
    "    weather_scen = noaa_weekly_all[noaa_weekly_all[\"year\"] == sampled_year].copy()\n",
    "    weather_scen = weather_scen.rename(columns={\"year\": \"sim_source_year\"})\n",
    "    # we'll merge on 'week'\n",
    "    return weather_scen[[\"week\", \"prcp_week_in\", \"TAVG\", \"TMAX\", \"TMIN\", \"AWND\"]]\n",
    "\n",
    "\n",
    "def apply_labor_uncertainty(wm_year: pd.DataFrame, rng: np.random.Generator, sd: float = 0.1):\n",
    "    mult = float(np.clip(rng.normal(loc=1.0, scale=sd), 0.7, 1.3))\n",
    "    wm_year = wm_year.copy()\n",
    "    wm_year[\"labor_hours\"] = wm_year[\"labor_hours\"] * mult\n",
    "    return wm_year, mult\n",
    "\n",
    "\n",
    "def run_monte_carlo_for_year(\n",
    "    noaa_weekly_all: pd.DataFrame,\n",
    "    n_scenarios: int = 50,\n",
    "    target_year: int = 2017,\n",
    "    random_seed: int = 42,\n",
    "    time_limit: int = 20,\n",
    "):\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    master = pd.read_csv(MASTER_PATH)\n",
    "    master_year_base = master[master[\"year\"] == target_year].copy()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for s in range(n_scenarios):\n",
    "        # 1) Copy base table\n",
    "        wm_scen = master_year_base.copy()\n",
    "\n",
    "        # 2) Sample weather year & merge weekly weather\n",
    "        weather_scen = sample_weather_year(noaa_weekly_all, target_year, rng)\n",
    "        wm_scen = wm_scen.drop(columns=[\"prcp_week_in\", \"TAVG\", \"TMAX\", \"TMIN\", \"AWND\"], errors=\"ignore\")\n",
    "        wm_scen = wm_scen.merge(weather_scen, on=\"week\", how=\"left\")\n",
    "\n",
    "        # 3) Recompute capacity_factor & harvest_weather_factor from weather\n",
    "        #    You'd reuse the same logic you used originally when building master_weekly\n",
    "        from src.optimization.weather_capacity import (\n",
    "            compute_capacity_factor,\n",
    "            compute_harvest_weather_factor,\n",
    "        )\n",
    "        wm_scen[\"capacity_factor\"] = wm_scen.apply(compute_capacity_factor, axis=1)\n",
    "        wm_scen[\"harvest_weather_factor\"] = wm_scen.apply(compute_harvest_weather_factor, axis=1)\n",
    "\n",
    "        # 4) Apply labor uncertainty\n",
    "        wm_scen, labor_mult = apply_labor_uncertainty(wm_scen, rng)\n",
    "\n",
    "        # 5) Save scenario copy to a temp CSV (simplest way to re-use MILP v2)\n",
    "        scen_path = Path(f\"data/processed/master_weekly_table_scen_{target_year}_{s}.csv\")\n",
    "        wm_full = master.copy()\n",
    "        wm_full.loc[wm_full[\"year\"] == target_year, wm_scen.columns] = wm_scen.values\n",
    "        wm_full.to_csv(scen_path, index=False)\n",
    "\n",
    "        # 6) Run MILP\n",
    "        sched_s = build_and_solve_schedule_v2(\n",
    "            weekly_master_path=str(scen_path),\n",
    "            target_year=target_year,\n",
    "            time_limit=time_limit,\n",
    "        )\n",
    "\n",
    "        makespan = float(sched_s[\"objective_makespan\"].iloc[0])\n",
    "        total_early = float(sched_s[\"early_penalty\"].sum())\n",
    "        total_late  = float(sched_s[\"late_penalty\"].sum())\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"scenario\": s,\n",
    "                \"labor_multiplier\": labor_mult,\n",
    "                \"makespan\": makespan,\n",
    "                \"total_early_penalty\": total_early,\n",
    "                \"total_late_penalty\": total_late,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimization.weather_capacity import (\n",
    "    compute_capacity_factor,\n",
    "    compute_harvest_weather_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaeaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_weekly_all = pd.read_csv(\"data/processed/noaa_il_weekly_clean.csv\")\n",
    "\n",
    "mc_results_2017 = run_monte_carlo_for_year(\n",
    "    noaa_weekly_all=noaa_weekly_all,\n",
    "    n_scenarios=50,\n",
    "    target_year=2017,\n",
    "    random_seed=123,\n",
    "    time_limit=20,\n",
    ")\n",
    "\n",
    "mc_results_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def summarize_mc_results(mc_results: pd.DataFrame, target_year: int = 2017):\n",
    "    \"\"\"Prints key risk metrics from Monte Carlo runs.\"\"\"\n",
    "    ms = mc_results[\"makespan\"].dropna().values\n",
    "    p50 = np.percentile(ms, 50)\n",
    "    p80 = np.percentile(ms, 80)\n",
    "    p95 = np.percentile(ms, 95)\n",
    "\n",
    "    print(f\"=== Monte Carlo Summary â€“ {target_year} ===\")\n",
    "    print(f\"Number of scenarios: {len(ms)}\")\n",
    "    print(f\"P50 makespan: {p50:.1f} (week)\")\n",
    "    print(f\"P80 makespan: {p80:.1f} (week)\")\n",
    "    print(f\"P95 makespan: {p95:.1f} (week)\")\n",
    "\n",
    "    # Example: risk of harvest going past week 42\n",
    "    prob_past_42 = np.mean(ms > 42) * 100\n",
    "    print(f\"Probability makespan > week 42: {prob_past_42:.1f}%\")\n",
    "\n",
    "    # Early vs late penalty averages\n",
    "    if \"total_early_penalty\" in mc_results.columns:\n",
    "        print(f\"Avg early penalty: {mc_results['total_early_penalty'].mean():.2f}\")\n",
    "    if \"total_late_penalty\" in mc_results.columns:\n",
    "        print(f\"Avg late penalty:  {mc_results['total_late_penalty'].mean():.2f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def plot_mc_visuals(mc_results: pd.DataFrame, target_year: int = 2017):\n",
    "    \"\"\"\n",
    "    Build Monte Carlo visuals:\n",
    "      1) Histogram of makespan with P50/P80/P95\n",
    "      2) CDF (risk curve) of makespan\n",
    "      3) Scatter: labor_multiplier vs makespan\n",
    "    \"\"\"\n",
    "    ms = mc_results[\"makespan\"].dropna().values\n",
    "    labor_mult = mc_results.get(\"labor_multiplier\", pd.Series([np.nan]*len(ms))).values\n",
    "\n",
    "    p50 = np.percentile(ms, 50)\n",
    "    p80 = np.percentile(ms, 80)\n",
    "    p95 = np.percentile(ms, 95)\n",
    "\n",
    "    # ---- 1 & 2: Histogram + CDF side by side ----\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # 1) Histogram\n",
    "    ax = axes[0]\n",
    "    ax.hist(ms, bins=10, alpha=0.7, edgecolor=\"black\")\n",
    "    ax.axvline(p50, color=\"green\", linestyle=\"--\", label=f\"P50 = {p50:.1f}\")\n",
    "    ax.axvline(p80, color=\"orange\", linestyle=\"--\", label=f\"P80 = {p80:.1f}\")\n",
    "    ax.axvline(p95, color=\"red\", linestyle=\"--\", label=f\"P95 = {p95:.1f}\")\n",
    "\n",
    "    ax.set_title(f\"Makespan Distribution â€“ {target_year}\")\n",
    "    ax.set_xlabel(\"Makespan (week of year)\")\n",
    "    ax.set_ylabel(\"Scenario count\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2) CDF (risk curve)\n",
    "    ax = axes[1]\n",
    "    ms_sorted = np.sort(ms)\n",
    "    cdf = np.arange(1, len(ms_sorted) + 1) / len(ms_sorted) * 100.0\n",
    "\n",
    "    ax.plot(ms_sorted, cdf, marker=\"o\")\n",
    "    ax.set_title(f\"Makespan Risk Curve â€“ {target_year}\")\n",
    "    ax.set_xlabel(\"Makespan (week of year)\")\n",
    "    ax.set_ylabel(\"Cumulative probability (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # mark P50/P80/P95 on curve\n",
    "    ax.axvline(p50, color=\"green\", linestyle=\"--\", alpha=0.6)\n",
    "    ax.axvline(p80, color=\"orange\", linestyle=\"--\", alpha=0.6)\n",
    "    ax.axvline(p95, color=\"red\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- 3: Labor multiplier vs makespan scatter ----\n",
    "    if \"labor_multiplier\" in mc_results.columns:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        ax.scatter(labor_mult, ms, alpha=0.7)\n",
    "        ax.set_xlabel(\"Labor multiplier (scenario-level)\")\n",
    "        ax.set_ylabel(\"Makespan (week of year)\")\n",
    "        ax.set_title(f\"Labor vs Makespan â€“ {target_year}\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No 'labor_multiplier' column found; skipping labor vs makespan scatter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_mc_results(mc_results_2017, target_year=2017)\n",
    "plot_mc_visuals(mc_results_2017, target_year=2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a232db",
   "metadata": {},
   "source": [
    "How to talk about these visuals in the interview\n",
    "\n",
    "You can frame it like:\n",
    "\n",
    "Histogram:\n",
    "\n",
    "â€œHere Iâ€™m showing the distribution of completion weeks across 50 simulated seasons.\n",
    "The median completion week is ~38, but under adverse weather/labor years, harvest can slip toward week 42â€“43.â€\n",
    "\n",
    "CDF (risk curve):\n",
    "\n",
    "â€œThis curve lets us answer questions like:\n",
    "â€˜Whatâ€™s the probability we finish by week 40?â€™\n",
    "In this case, about X% of scenarios complete by week 40, and P80 sits around week Y.â€\n",
    "\n",
    "Labor vs makespan:\n",
    "\n",
    "â€œThis scatter shows that when seasonal labor availability drops below ~0.9Ã— baseline, makespan quickly increases, indicating that the system is more sensitive to labor shortages than small variations in machinery capacity.â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cde7a",
   "metadata": {},
   "source": [
    "# âœ… A. Tornado Sensitivity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805aa451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tornado_sensitivity(mc_results, title=\"Tornado Sensitivity â€“ Makespan\"):\n",
    "    \"\"\"\n",
    "    Computes simple correlation-based sensitivity.\n",
    "    Higher absolute correlation â†’ stronger influence on makespan.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select numeric scenario inputs\n",
    "    numeric_cols = [\n",
    "        c for c in mc_results.columns\n",
    "        if c not in (\"scenario\", \"makespan\")\n",
    "    ]\n",
    "\n",
    "    # Compute correlations with makespan\n",
    "    corr = mc_results[numeric_cols].corrwith(mc_results[\"makespan\"]).abs()\n",
    "    corr_sorted = corr.sort_values(ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    plt.barh(corr_sorted.index, corr_sorted.values, color=\"orange\", alpha=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Absolute correlation with makespan\")\n",
    "    plt.grid(axis=\"x\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return corr_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f35bf",
   "metadata": {},
   "source": [
    "# âœ… B. Scenario Clustering\n",
    "\n",
    "Group into:\n",
    "\n",
    "Early finish (bottom ~33%)\n",
    "\n",
    "Average finish (middle)\n",
    "\n",
    "Late finish (top ~33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d16f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_scenarios(mc_results):\n",
    "    \"\"\"\n",
    "    Creates categorical cluster: Early / Normal / Late based on quantiles.\n",
    "    \"\"\"\n",
    "    ms = mc_results[\"makespan\"]\n",
    "    q1 = ms.quantile(0.33)\n",
    "    q2 = ms.quantile(0.66)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= q1:\n",
    "            return \"Early\"\n",
    "        elif x <= q2:\n",
    "            return \"Normal\"\n",
    "        else:\n",
    "            return \"Late\"\n",
    "\n",
    "    mc_results[\"cluster\"] = ms.apply(classify)\n",
    "    return mc_results\n",
    "\n",
    "\n",
    "def plot_cluster_boxplot(mc_results, target_year=2017):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.boxplot(data=mc_results, x=\"cluster\", y=\"makespan\", palette=\"Set2\")\n",
    "    plt.title(f\"Monte Carlo Scenario Clusters â€“ {target_year}\")\n",
    "    plt.ylabel(\"Makespan (week)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a0d5850",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_scenarios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mc_clustered_2017 = \u001b[43mcluster_scenarios\u001b[49m(mc_results_2017)\n\u001b[32m      2\u001b[39m plot_cluster_boxplot(mc_clustered_2017)\n",
      "\u001b[31mNameError\u001b[39m: name 'cluster_scenarios' is not defined"
     ]
    }
   ],
   "source": [
    "mc_clustered_2017 = cluster_scenarios(mc_results_2017)\n",
    "plot_cluster_boxplot(mc_clustered_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32dfbd",
   "metadata": {},
   "source": [
    "# Multi-Year Risk Curves (CDF overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_curve_overlay(mc_dict):\n",
    "    \"\"\"\n",
    "    mc_dict = {\n",
    "        2017: df,\n",
    "        2018: df,\n",
    "        2019: df,\n",
    "        2020: df\n",
    "    }\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for year, df in mc_dict.items():\n",
    "        ms = np.sort(df[\"makespan\"])\n",
    "        cdf = np.arange(1, len(ms)+1) / len(ms) * 100\n",
    "        plt.plot(ms, cdf, marker=\".\", label=str(year))\n",
    "\n",
    "    plt.title(\"Risk Curves â€“ Multi-year Monte Carlo\")\n",
    "    plt.xlabel(\"Makespan (week of year)\")\n",
    "    plt.ylabel(\"Cumulative probability (%)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2017, 2018, 2019, 2020]\n",
    "mc_multi = {}\n",
    "\n",
    "for yr in years:\n",
    "    mc_multi[yr] = run_monte_carlo_for_year(\n",
    "        noaa_weekly_all=noaa_weekly_all,\n",
    "        n_scenarios=80,\n",
    "        target_year=yr,\n",
    "        random_seed=yr,\n",
    "        time_limit=20\n",
    "    )\n",
    "\n",
    "risk_curve_overlay(mc_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a7a8d",
   "metadata": {},
   "source": [
    "# Run 1000 Simulations (Stable & Fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_1000 = run_monte_carlo_for_year(\n",
    "    noaa_weekly_all=noaa_weekly_all,\n",
    "    n_scenarios=1000,\n",
    "    target_year=2017,\n",
    "    random_seed=999,\n",
    "    time_limit=2,     # IMPORTANT: tiny time limit per model\n",
    ")\n",
    "\n",
    "summarize_mc_results(mc_1000, target_year=2017)\n",
    "plot_mc_visuals(mc_1000, target_year=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_mc_risk_summary_figure(mc_results: pd.DataFrame,\n",
    "                                 target_year: int = 2017,\n",
    "                                 save_path: str | None = None):\n",
    "    \"\"\"\n",
    "    Create a 2x2 Monte Carlo risk summary figure:\n",
    "      (1,1) Makespan histogram with P50/P80/P95\n",
    "      (1,2) Makespan CDF (risk curve)\n",
    "      (2,1) Tornado-style sensitivity (abs corr with makespan)\n",
    "      (2,2) Labor multiplier vs makespan scatter\n",
    "\n",
    "    mc_results should at least have:\n",
    "      ['scenario', 'makespan', 'labor_multiplier', ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # ------- basic stats -------\n",
    "    ms = mc_results[\"makespan\"].dropna().values\n",
    "    p50 = np.percentile(ms, 50)\n",
    "    p80 = np.percentile(ms, 80)\n",
    "    p95 = np.percentile(ms, 95)\n",
    "    prob_past_42 = np.mean(ms > 42) * 100\n",
    "\n",
    "    # sensitivity (tornado) â€“ absolute correlation with makespan\n",
    "    numeric_cols = [\n",
    "        c for c in mc_results.columns\n",
    "        if c not in (\"scenario\", \"makespan\")\n",
    "        and pd.api.types.is_numeric_dtype(mc_results[c])\n",
    "    ]\n",
    "    corr = mc_results[numeric_cols].corrwith(mc_results[\"makespan\"]).abs()\n",
    "    corr_sorted = corr.sort_values(ascending=True)\n",
    "\n",
    "    # ------- figure layout -------\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "\n",
    "    # ---- (1,1) histogram ----\n",
    "    ax = axes[0, 0]\n",
    "    ax.hist(ms, bins=10, alpha=0.7, edgecolor=\"black\")\n",
    "    ax.axvline(p50, color=\"green\", linestyle=\"--\", label=f\"P50={p50:.1f}\")\n",
    "    ax.axvline(p80, color=\"orange\", linestyle=\"--\", label=f\"P80={p80:.1f}\")\n",
    "    ax.axvline(p95, color=\"red\", linestyle=\"--\", label=f\"P95={p95:.1f}\")\n",
    "    ax.set_title(f\"Makespan Distribution â€“ {target_year}\")\n",
    "    ax.set_xlabel(\"Makespan (week of year)\")\n",
    "    ax.set_ylabel(\"Scenario count\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "    # small text box with risk metric\n",
    "    text = f\"Pr(makespan > 42) = {prob_past_42:.1f}%\"\n",
    "    ax.text(0.99, 0.95, text,\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "    # ---- (1,2) CDF risk curve ----\n",
    "    ax = axes[0, 1]\n",
    "    ms_sorted = np.sort(ms)\n",
    "    cdf = np.arange(1, len(ms_sorted) + 1) / len(ms_sorted) * 100.0\n",
    "    ax.plot(ms_sorted, cdf, marker=\"o\")\n",
    "    ax.axvline(p50, color=\"green\", linestyle=\"--\", alpha=0.6)\n",
    "    ax.axvline(p80, color=\"orange\", linestyle=\"--\", alpha=0.6)\n",
    "    ax.axvline(p95, color=\"red\", linestyle=\"--\", alpha=0.6)\n",
    "    ax.set_title(\"Makespan Risk Curve (CDF)\")\n",
    "    ax.set_xlabel(\"Makespan (week of year)\")\n",
    "    ax.set_ylabel(\"Cumulative probability (%)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # ---- (2,1) Tornado sensitivity ----\n",
    "    ax = axes[1, 0]\n",
    "    ax.barh(corr_sorted.index, corr_sorted.values, alpha=0.8)\n",
    "    ax.set_title(\"Sensitivity (Tornado) â€“ abs corr with makespan\")\n",
    "    ax.set_xlabel(\"Absolute correlation\")\n",
    "    ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "    # ---- (2,2) Labor vs makespan ----\n",
    "    ax = axes[1, 1]\n",
    "    if \"labor_multiplier\" in mc_results.columns:\n",
    "        ax.scatter(mc_results[\"labor_multiplier\"], mc_results[\"makespan\"], alpha=0.7)\n",
    "        ax.set_xlabel(\"Labor multiplier\")\n",
    "    else:\n",
    "        ax.scatter(range(len(ms)), ms, alpha=0.7)\n",
    "        ax.set_xlabel(\"Scenario index\")\n",
    "\n",
    "    ax.set_ylabel(\"Makespan (week)\")\n",
    "    ax.set_title(\"Labor vs Makespan\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"Monte Carlo Risk Summary â€“ {target_year}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Return stats so you can paste them into slide notes\n",
    "    return {\n",
    "        \"P50\": p50,\n",
    "        \"P80\": p80,\n",
    "        \"P95\": p95,\n",
    "        \"Prob_past_42\": prob_past_42,\n",
    "        \"corr_sorted\": corr_sorted.sort_values(ascending=False),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_2017 = build_mc_risk_summary_figure(\n",
    "    mc_results_2017,\n",
    "    target_year=2017,\n",
    "    save_path=\"figures/mc_risk_summary_2017.png\",   # or None\n",
    ")\n",
    "\n",
    "stats_2017[\"P50\"], stats_2017[\"P80\"], stats_2017[\"P95\"], stats_2017[\"Prob_past_42\"]\n",
    "stats_2017[\"corr_sorted\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c4271",
   "metadata": {},
   "source": [
    "# how can I use my Monte carlo simulation as an input to my Gurobi model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129b9b4",
   "metadata": {},
   "source": [
    "You donâ€™t make Gurobi â€œrandomâ€ â€“ you use Monte Carlo in Python to generate scenario data, then feed those scenarios into Gurobi as deterministic parameters in either:\n",
    "\n",
    "a wrapper (what youâ€™re already doing), or\n",
    "\n",
    "a single scenario-based / stochastic MILP where capacities & labor depend on scenario.\n",
    "\n",
    "Let me walk through both and show how to do (2), which is probably what youâ€™re asking.\n",
    "\n",
    "1ï¸âƒ£ What youâ€™re already doing (optimize-then-simulate)\n",
    "\n",
    "Right now your flow is:\n",
    "\n",
    "Sample a weather + labor scenario in Python.\n",
    "\n",
    "Build a scenario-specific weekly_master.\n",
    "\n",
    "Call build_and_solve_schedule_v2(...) once per scenario.\n",
    "\n",
    "Collect makespan, penalties, etc.\n",
    "\n",
    "This already uses Monte Carlo as input to Gurobi â€“ but one scenario at a time.\n",
    "\n",
    "Pros: simple; each MILP stays small.\n",
    "Cons: Gurobi never sees all scenarios at once, so you canâ€™t ask â€œfind a schedule that is good across all scenariosâ€.\n",
    "\n",
    "Thatâ€™s where (2) comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054b527",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "Use Monte Carlo to create S scenarios of weekly capacities & labor.\n",
    "\n",
    "Build one big MILP that has:\n",
    "\n",
    "First-stage decisions: planting/harvest decisions shared by all scenarios.\n",
    "\n",
    "Scenario-specific constraints: capacity, labor, penalties per scenario.\n",
    "\n",
    "Objective: minimize expected penalty / makespan across scenarios (or worst-case).\n",
    "\n",
    "Step 2.1 â€“ Build a scenario table from Monte Carlo\n",
    "\n",
    "Instead of solving the MILP inside your MC loop, stop just before the solve and store the sampled capacities/labor:\n",
    "\n",
    "2ï¸âƒ£ Scenario-based / â€œstochasticâ€ MILP (Monte Carlo inside the model)\n",
    "\n",
    "Idea:\n",
    "\n",
    "Use Monte Carlo to create S scenarios of weekly capacities & labor.\n",
    "\n",
    "Build one big MILP that has:\n",
    "\n",
    "First-stage decisions: planting/harvest decisions shared by all scenarios.\n",
    "\n",
    "Scenario-specific constraints: capacity, labor, penalties per scenario.\n",
    "\n",
    "Objective: minimize expected penalty / makespan across scenarios (or worst-case).\n",
    "\n",
    "Step 2.1 â€“ Build a scenario table from Monte Carlo\n",
    "\n",
    "Instead of solving the MILP inside your MC loop, stop just before the solve and store the sampled capacities/labor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios(noaa_weekly_all, master, target_year=2017, n_scenarios=50, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    base_year = master[master[\"year\"] == target_year].copy()\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for s in range(n_scenarios):\n",
    "        wm_scen = base_year.copy()\n",
    "\n",
    "        # sample weather & recompute factors (same logic you already use)\n",
    "        weather_scen = sample_weather_year(noaa_weekly_all, target_year, rng)\n",
    "        wm_scen = wm_scen.drop(columns=[\"prcp_week_in\", \"TAVG\", \"TMAX\", \"TMIN\", \"AWND\"], errors=\"ignore\")\n",
    "        wm_scen = wm_scen.merge(weather_scen, on=\"week\", how=\"left\")\n",
    "\n",
    "        wm_scen[\"capacity_factor\"] = wm_scen.apply(compute_capacity_factor, axis=1)\n",
    "        wm_scen[\"harvest_weather_factor\"] = wm_scen.apply(compute_harvest_weather_factor, axis=1)\n",
    "\n",
    "        wm_scen, labor_mult = apply_labor_uncertainty(wm_scen, rng)\n",
    "\n",
    "        for _, row in wm_scen.iterrows():\n",
    "            records.append({\n",
    "                \"scenario\": s,\n",
    "                \"week\": int(row[\"week\"]),\n",
    "                \"capacity_factor\": float(row[\"capacity_factor\"]),\n",
    "                \"harvest_weather_factor\": float(row[\"harvest_weather_factor\"]),\n",
    "                \"labor_hours\": float(row[\"labor_hours\"]),\n",
    "            })\n",
    "\n",
    "    scen_df = pd.DataFrame(records)\n",
    "    return scen_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc21cc1",
   "metadata": {},
   "source": [
    "Step 2.2 â€“ Build a scenario MILP in Gurobi\n",
    "\n",
    "Indices:\n",
    "\n",
    "F = fields\n",
    "\n",
    "W = weeks\n",
    "\n",
    "S = scenarios\n",
    "\n",
    "Data:\n",
    "\n",
    "area[f] from your fields table\n",
    "\n",
    "cap_planter[w,s] = base_planter_capacity * capacity_factor[w,s]\n",
    "\n",
    "cap_harvester[w,s] = base_harvester_capacity * harvest_weather_factor[w,s]\n",
    "\n",
    "labor[w,s] = labor_hours[w,s]\n",
    "\n",
    "Variables:\n",
    "\n",
    "Plant[f,w] âˆˆ {0,1} â€“ field f planted in week w (shared across scenarios)\n",
    "\n",
    "Harvest[f,w] âˆˆ {0,1} â€“ field f harvested in week w (shared)\n",
    "\n",
    "(Optional) scenario-specific slack / delay: LateSlack[f,s] â‰¥ 0, Delay[s] â‰¥ 0\n",
    "\n",
    "Objective:\n",
    "\n",
    "minimize average Delay[s] or average LateSlack[f,s] (expected penalty)\n",
    "or max_s Delay[s] (robust worst-case).\n",
    "\n",
    "Skeleton code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4894b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "def build_stochastic_schedule(fields_df, scen_df,\n",
    "                              base_planter_capacity=1400.0,\n",
    "                              base_harvester_capacity=950.0,\n",
    "                              labor_plant_per_acre=0.15,\n",
    "                              labor_harvest_per_acre=0.20,\n",
    "                              min_harvest_lag_weeks=6):\n",
    "\n",
    "    fields = fields_df[\"field_id\"].tolist()\n",
    "    area = dict(zip(fields_df[\"field_id\"], fields_df[\"acres\"]))\n",
    "\n",
    "    weeks = sorted(scen_df[\"week\"].unique().tolist())\n",
    "    scenarios = sorted(scen_df[\"scenario\"].unique().tolist())\n",
    "\n",
    "    # capacity dictionaries indexed by (w,s)\n",
    "    cap_plant = {}\n",
    "    cap_harvest = {}\n",
    "    labor_cap = {}\n",
    "\n",
    "    for _, row in scen_df.iterrows():\n",
    "        w = int(row[\"week\"])\n",
    "        s = int(row[\"scenario\"])\n",
    "        cap_plant[w, s] = base_planter_capacity * row[\"capacity_factor\"]\n",
    "        cap_harvest[w, s] = base_harvester_capacity * row[\"harvest_weather_factor\"]\n",
    "        labor_cap[w, s] = row[\"labor_hours\"]\n",
    "\n",
    "    m = gp.Model(\"stochastic_corn_schedule\")\n",
    "\n",
    "    # 1) First-stage decisions (same across scenarios)\n",
    "    Plant = m.addVars(fields, weeks, vtype=GRB.BINARY, name=\"Plant\")\n",
    "    Harvest = m.addVars(fields, weeks, vtype=GRB.BINARY, name=\"Harvest\")\n",
    "\n",
    "    # 2) Scenario-level delay variable\n",
    "    Delay = m.addVars(scenarios, lb=0.0, name=\"Delay\")\n",
    "\n",
    "    # --- constraints ---\n",
    "\n",
    "    # Each field planted & harvested exactly once (like before)\n",
    "    for f in fields:\n",
    "        m.addConstr(gp.quicksum(Plant[f, w] for w in weeks) == 1, name=f\"PlantOnce_{f}\")\n",
    "        m.addConstr(gp.quicksum(Harvest[f, w] for w in weeks) == 1, name=f\"HarvestOnce_{f}\")\n",
    "\n",
    "    # Harvest after planting + minimum lag\n",
    "    for f in fields:\n",
    "        for wp in weeks:\n",
    "            for wh in weeks:\n",
    "                if wh < wp + min_harvest_lag_weeks:\n",
    "                    m.addConstr(Plant[f, wp] + Harvest[f, wh] <= 1,\n",
    "                                name=f\"NoEarlyHarvest_{f}_{wp}_{wh}\")\n",
    "\n",
    "    # Scenario-specific weekly capacities\n",
    "    for s in scenarios:\n",
    "        for w in weeks:\n",
    "            # planter capacity\n",
    "            m.addConstr(\n",
    "                gp.quicksum(area[f] * Plant[f, w] for f in fields)\n",
    "                <= cap_plant[w, s],\n",
    "                name=f\"PlantCap_w{w}_s{s}\"\n",
    "            )\n",
    "\n",
    "            # harvester capacity\n",
    "            m.addConstr(\n",
    "                gp.quicksum(area[f] * Harvest[f, w] for f in fields)\n",
    "                <= cap_harvest[w, s],\n",
    "                name=f\"HarvCap_w{w}_s{s}\"\n",
    "            )\n",
    "\n",
    "            # labor capacity (plant + harvest)\n",
    "            labor_need = gp.quicksum(\n",
    "                area[f] * labor_plant_per_acre * Plant[f, w]\n",
    "                + area[f] * labor_harvest_per_acre * Harvest[f, w]\n",
    "                for f in fields\n",
    "            )\n",
    "            m.addConstr(\n",
    "                labor_need <= labor_cap[w, s],\n",
    "                name=f\"LaborCap_w{w}_s{s}\"\n",
    "            )\n",
    "\n",
    "        # define scenario-level completion week (Delay[s])\n",
    "        # here as proxy: last harvest week used\n",
    "        m.addConstr(\n",
    "            Delay[s] >= gp.quicksum(w * Harvest[f, w] for f in fields for w in weeks) /\n",
    "                        len(fields),\n",
    "            name=f\"DelayDef_s{s}\"\n",
    "        )\n",
    "\n",
    "    # objective: minimize expected completion week across scenarios\n",
    "    m.setObjective(\n",
    "        (1 / len(scenarios)) * gp.quicksum(Delay[s] for s in scenarios),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    m.optimize()\n",
    "    return m, Plant, Harvest, Delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f395d75c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstochastic_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     generate_scenarios_for_year,\n\u001b[32m      3\u001b[39m     build_stochastic_schedule,\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m scenario_df_2017 = generate_scenarios_for_year(\n\u001b[32m      7\u001b[39m     noaa_weekly_path=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/noaa_il_weekly_clean.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     weekly_master_path=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/master_weekly_table.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     labor_sd=\u001b[32m0.1\u001b[39m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m schedule_robust_2017, status = build_stochastic_schedule(\n\u001b[32m     16\u001b[39m     fields_path=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/illinois_corn_fields_clean.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     weekly_master_path=\u001b[33m\"\u001b[39m\u001b[33mdata/processed/master_weekly_table.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     time_limit=\u001b[32m120\u001b[39m,\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.optimization.stochastic_scheduler import (\n",
    "    generate_scenarios_for_year,\n",
    "    build_stochastic_schedule,\n",
    ")\n",
    "\n",
    "scenario_df_2017 = generate_scenarios_for_year(\n",
    "    noaa_weekly_path=\"data/processed/noaa_il_weekly_clean.csv\",\n",
    "    weekly_master_path=\"data/processed/master_weekly_table.csv\",\n",
    "    target_year=2017,\n",
    "    n_scenarios=10,       # keep this small for license / runtime\n",
    "    random_seed=123,\n",
    "    labor_sd=0.1,\n",
    ")\n",
    "\n",
    "schedule_robust_2017, status = build_stochastic_schedule(\n",
    "    fields_path=\"data/processed/illinois_corn_fields_clean.csv\",\n",
    "    weekly_master_path=\"data/processed/master_weekly_table.csv\",\n",
    "    scenario_df=scenario_df_2017,\n",
    "    target_year=2017,\n",
    "    base_planter_capacity=1400.0,\n",
    "    base_harvester_capacity=950.0,\n",
    "    labor_plant_per_acre=0.15,\n",
    "    labor_harvest_per_acre=0.20,\n",
    "    min_harvest_lag_weeks=6,\n",
    "    time_limit=120,\n",
    ")\n",
    "\n",
    "schedule_robust_2017.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db2c9d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scenario_df_2017' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m bad_rhs = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mscenario_df_2017\u001b[49m.iterrows():\n\u001b[32m      4\u001b[39m     w = \u001b[38;5;28mint\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mweek\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m     s = \u001b[38;5;28mint\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'scenario_df_2017' is not defined"
     ]
    }
   ],
   "source": [
    "bad_rhs = []\n",
    "\n",
    "for idx, row in scenario_df_2017.iterrows():\n",
    "    w = int(row[\"week\"])\n",
    "    s = int(row[\"scenario\"])\n",
    "    if pd.isna(row[\"labor_hours\"]) or pd.isna(row[\"capacity_factor\"]) or pd.isna(row[\"harvest_weather_factor\"]):\n",
    "        bad_rhs.append((w, s, row))\n",
    "\n",
    "bad_rhs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8f978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
