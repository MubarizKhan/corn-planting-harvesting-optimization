{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6db63438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b47b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   year  week  prcp_week_in       TMAX       TMIN       TAVG       AWND\n",
       " 0  2017     1          0.77  22.285714   7.742857  15.414286  10.685714\n",
       " 1  2017     2          3.14  34.857143  18.685714  26.528571  10.742857\n",
       " 2  2017     3          7.84  45.628571  34.285714  39.914286   8.432143\n",
       " 3  2017     4          0.38  35.257143  29.000000  32.428571  11.775000\n",
       " 4  2017     5          0.19  35.057143  19.342857  27.300000  11.800000,\n",
       "    Year  week week_ending  pct_planted\n",
       " 0  2005    15  2005-04-17         35.0\n",
       " 1  2005    16  2005-04-24         64.0\n",
       " 2  2005    17  2005-05-01         82.0\n",
       " 3  2005    18  2005-05-08         94.0\n",
       " 4  2005    19  2005-05-15         98.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned weekly planting data and NOAA weather aggregation\n",
    "weather_path = \"../../data/processed/noaa_il_weekly_agg.csv\"\n",
    "planting_path = \"../../data/processed/nass_corn_planting_weekly_clean.csv\"\n",
    "\n",
    "# Load data\n",
    "weather_df = pd.read_csv(weather_path)\n",
    "planting_df = pd.read_csv(planting_path)\n",
    "\n",
    "# Preview\n",
    "weather_df.head(), planting_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c04b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>week_ending</th>\n",
       "      <th>pct_planted</th>\n",
       "      <th>prcp_week_in</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.92</td>\n",
       "      <td>59.542857</td>\n",
       "      <td>42.657143</td>\n",
       "      <td>50.814286</td>\n",
       "      <td>13.278571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>67.485714</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>57.157143</td>\n",
       "      <td>10.903571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>16</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>67.171429</td>\n",
       "      <td>44.514286</td>\n",
       "      <td>55.885714</td>\n",
       "      <td>10.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>45.714286</td>\n",
       "      <td>54.457143</td>\n",
       "      <td>12.653571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>58.228571</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>50.242857</td>\n",
       "      <td>12.178571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week week_ending  pct_planted  prcp_week_in       TMAX       TMIN  \\\n",
       "0  2017    14  2017-04-09          1.0          6.92  59.542857  42.657143   \n",
       "1  2017    15  2017-04-16          6.0          6.22  67.485714  46.600000   \n",
       "2  2017    16  2017-04-23         34.0          1.28  67.171429  44.514286   \n",
       "3  2017    17  2017-04-30         63.0         15.96  62.800000  45.714286   \n",
       "4  2017    18  2017-05-07         65.0          3.40  58.228571  42.142857   \n",
       "\n",
       "        TAVG       AWND  \n",
       "0  50.814286  13.278571  \n",
       "1  57.157143  10.903571  \n",
       "2  55.885714  10.325000  \n",
       "3  54.457143  12.653571  \n",
       "4  50.242857  12.178571  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv(weather_path)\n",
    "planting_df = pd.read_csv(planting_path)\n",
    "\n",
    "# Standardize column names to match on 'year' and 'week'\n",
    "planting_df = planting_df.rename(columns={\"Year\": \"year\"})\n",
    "\n",
    "# Merge on 'year' and 'week'\n",
    "merged_df = pd.merge(planting_df, weather_df, on=[\"year\", \"week\"], how=\"inner\")\n",
    "\n",
    "# Display merged dataset structure\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56a166e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant year column\n",
    "merged_df.drop(columns=[\"year\"], inplace=True)\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "merged_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a99cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_path = \"/../../data/processed/merged_planting_weather.csv\"\n",
    "# merged_df = pd.to_csv(merged_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "784485cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>week_ending</th>\n",
       "      <th>pct_planted</th>\n",
       "      <th>prcp_week_in</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>AWND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.92</td>\n",
       "      <td>59.542857</td>\n",
       "      <td>42.657143</td>\n",
       "      <td>50.814286</td>\n",
       "      <td>13.278571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>67.485714</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>57.157143</td>\n",
       "      <td>10.903571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>16</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>67.171429</td>\n",
       "      <td>44.514286</td>\n",
       "      <td>55.885714</td>\n",
       "      <td>10.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>45.714286</td>\n",
       "      <td>54.457143</td>\n",
       "      <td>12.653571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>58.228571</td>\n",
       "      <td>42.142857</td>\n",
       "      <td>50.242857</td>\n",
       "      <td>12.178571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week week_ending  pct_planted  prcp_week_in       TMAX       TMIN  \\\n",
       "0  2017    14  2017-04-09          1.0          6.92  59.542857  42.657143   \n",
       "1  2017    15  2017-04-16          6.0          6.22  67.485714  46.600000   \n",
       "2  2017    16  2017-04-23         34.0          1.28  67.171429  44.514286   \n",
       "3  2017    17  2017-04-30         63.0         15.96  62.800000  45.714286   \n",
       "4  2017    18  2017-05-07         65.0          3.40  58.228571  42.142857   \n",
       "\n",
       "        TAVG       AWND  \n",
       "0  50.814286  13.278571  \n",
       "1  57.157143  10.903571  \n",
       "2  55.885714  10.325000  \n",
       "3  54.457143  12.653571  \n",
       "4  50.242857  12.178571  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix column name for consistency\n",
    "planting_df = planting_df.rename(columns={\"Year\": \"year\"})\n",
    "\n",
    "# Merge again\n",
    "merged_df = pd.merge(planting_df, weather_df, on=[\"year\", \"week\"], how=\"inner\")\n",
    "\n",
    "# Drop rows with missing planting data\n",
    "merged_df = merged_df.dropna(subset=[\"pct_planted\"])\n",
    "\n",
    "# Sort for lag features\n",
    "merged_df = merged_df.sort_values(by=[\"year\", \"week\"]).reset_index(drop=True)\n",
    "\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f25de",
   "metadata": {},
   "source": [
    "# ✅ 1. Temporal Features (Most Important)\n",
    "Planting is a cumulative seasonal process. Your model must understand time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8d86429",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"week_number\"] = merged_df[\"week\"]\n",
    "merged_df[\"cos_week\"] = np.cos(2 * np.pi * merged_df[\"week\"] / 52)\n",
    "merged_df[\"sin_week\"] = np.sin(2 * np.pi * merged_df[\"week\"] / 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323434d1",
   "metadata": {},
   "source": [
    "# ✅ 2. Lag Features (Huge performance boost)\n",
    "Planting progress this week depends on last week’s progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f66d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"pct_lag_1\"] = merged_df.groupby(\"year\")[\"pct_planted\"].shift(1)\n",
    "merged_df[\"pct_lag_2\"] = merged_df.groupby(\"year\")[\"pct_planted\"].shift(2)\n",
    "merged_df[\"pct_weekly_change\"] = merged_df.groupby(\"year\")[\"pct_planted\"].diff()\n",
    "merged_df[\"pct_weekly_change_pct\"] = merged_df.groupby(\"year\")[\"pct_planted\"].pct_change()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09ba68",
   "metadata": {},
   "source": [
    "# ✅ 3. Add Growing Degree Days (GDD)\n",
    "Corn growth and planting conditions correlate strongly with heat accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "734b4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"gdd\"] = np.maximum(merged_df[\"TAVG\"] - 10, 0)\n",
    "merged_df[\"gdd_cum\"] = merged_df.groupby(\"year\")[\"gdd\"].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff43775",
   "metadata": {},
   "source": [
    "# ✅ 4. Add Soil Moisture Proxy (Rainfall Memory)\n",
    "This is extremely predictive of planting delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4d72cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"rain_last_week\"] = merged_df.groupby(\"year\")[\"prcp_week_in\"].shift(1)\n",
    "merged_df[\"rain_2wk\"] = merged_df.groupby(\"year\")[\"prcp_week_in\"].rolling(2).sum().reset_index(0,drop=True)\n",
    "merged_df[\"rain_3wk\"] = merged_df.groupby(\"year\")[\"prcp_week_in\"].rolling(3).sum().reset_index(0,drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7aab1",
   "metadata": {},
   "source": [
    "# ✅ 5. Add Drying Index\n",
    "Warmer + windier weather dries the soil faster, allowing machinery to enter fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3768b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"drying_index\"] = merged_df[\"TAVG\"] * merged_df[\"AWND\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815a6af",
   "metadata": {},
   "source": [
    "# ✅ 6. Add Anomalies (Deviation from Normal)\n",
    "Weekly normals matter in agronomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90de961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"tavg_anomaly\"] = merged_df[\"TAVG\"] - merged_df.groupby(\"week\")[\"TAVG\"].transform(\"mean\")\n",
    "merged_df[\"prcp_anomaly\"] = merged_df[\"prcp_week_in\"] - merged_df.groupby(\"week\")[\"prcp_week_in\"].transform(\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c91b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6164a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'week', 'week_ending', 'pct_planted', 'prcp_week_in', 'TMAX',\n",
       "       'TMIN', 'TAVG', 'AWND', 'week_number', 'cos_week', 'sin_week',\n",
       "       'pct_lag_1', 'pct_lag_2', 'pct_weekly_change', 'pct_weekly_change_pct',\n",
       "       'gdd', 'gdd_cum', 'rain_last_week', 'rain_2wk', 'rain_3wk',\n",
       "       'drying_index', 'tavg_anomaly', 'prcp_anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f02dab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_df['week_ending']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0f1e7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from xgboost) (2.28.9)\n",
      "Requirement already satisfied: scipy in /home/mak/Documents/Optimization/Project/.venv/lib/python3.12/site-packages (from xgboost) (1.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29c3f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost \n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ed15009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/2558845506.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pct_weekly_change_pct    3\n",
       "week                     0\n",
       "year                     0\n",
       "prcp_week_in             0\n",
       "TMAX                     0\n",
       "TMIN                     0\n",
       "pct_planted              0\n",
       "TAVG                     0\n",
       "AWND                     0\n",
       "cos_week                 0\n",
       "week_number              0\n",
       "sin_week                 0\n",
       "pct_lag_1                0\n",
       "pct_lag_2                0\n",
       "pct_weekly_change        0\n",
       "gdd                      0\n",
       "gdd_cum                  0\n",
       "rain_last_week           0\n",
       "rain_2wk                 0\n",
       "rain_3wk                 0\n",
       "drying_index             0\n",
       "tavg_anomaly             0\n",
       "prcp_anomaly             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "merged_df.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65cf1c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/1863058129.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[\"pct_weekly_change_pct\"] = merged_df[\"pct_weekly_change_pct\"].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# merged_df[\"week_ending\"] = pd.to_datetime(merged_df[\"week_ending\"]).astype(int) // 10**9\n",
    "merged_df[\"pct_weekly_change_pct\"] = merged_df[\"pct_weekly_change_pct\"].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c369867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29.18326972312897, 0.9726728828800253)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features and target\n",
    "features = ['year', 'week', 'prcp_week_in', 'TMAX','TMIN', 'TAVG', 'AWND',\n",
    "            'week_number', 'cos_week', 'sin_week','pct_lag_1', 'pct_lag_2', 'pct_weekly_change',\n",
    "            'pct_weekly_change_pct','gdd', 'gdd_cum', 'rain_last_week', 'rain_2wk', 'rain_3wk',\n",
    "            'drying_index', 'tavg_anomaly', 'prcp_anomaly']\n",
    "target = \"pct_planted\"\n",
    "\n",
    "# Drop rows with missing values\n",
    "merged_df = merged_df.dropna(subset=features + [target])\n",
    "\n",
    "# Split into train and test sets\n",
    "X = merged_df[features]\n",
    "y = merged_df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost regressor\n",
    "model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43d9ce1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.506746566412403, 0.9895391727119648)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert year to int if needed\n",
    "merged_df[\"year\"] = merged_df[\"year\"].astype(int)\n",
    "\n",
    "# Define train and test split by year\n",
    "train_df = merged_df[merged_df[\"year\"] <= 2022]\n",
    "test_df  = merged_df[merged_df[\"year\"] == 2023]\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_test  = test_df[features]\n",
    "y_test  = test_df[target]\n",
    "\n",
    "# Train XGBoost\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb2e06c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "clip() got an unexpected keyword argument 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Calculate additional metrics\u001b[39;00m\n\u001b[32m     15\u001b[39m rf_mae = mean_absolute_error(y_test, rf_preds)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m rf_msle = mean_squared_log_error(\u001b[43my_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m, rf_preds.clip(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m))\n\u001b[32m     18\u001b[39m lr_mae = mean_absolute_error(y_test, lr_preds)\n\u001b[32m     19\u001b[39m lr_msle = mean_squared_log_error(y_test.clip(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m), lr_preds.clip(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/core/generic.py:9093\u001b[39m, in \u001b[36mNDFrame.clip\u001b[39m\u001b[34m(self, lower, upper, axis, inplace, **kwargs)\u001b[39m\n\u001b[32m   9086\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ctr <= ref_count:\n\u001b[32m   9087\u001b[39m             warnings.warn(\n\u001b[32m   9088\u001b[39m                 _chained_assignment_warning_method_msg,\n\u001b[32m   9089\u001b[39m                 \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   9090\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   9091\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m9093\u001b[39m axis = \u001b[43mnv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_clip_with_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9094\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9095\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/compat/numpy/function.py:206\u001b[39m, in \u001b[36mvalidate_clip_with_axis\u001b[39m\u001b[34m(axis, args, kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"None\",\u001b[39;00m\n\u001b[32m    203\u001b[39m     \u001b[38;5;66;03m# variable has type \"Union[ndarray[Any, Any], str, int]\")\u001b[39;00m\n\u001b[32m    204\u001b[39m     axis = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43mvalidate_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ndarray[Any, Any],\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# str, int]\", expected \"Union[str, int, None]\")\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m axis\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/compat/numpy/function.py:88\u001b[39m, in \u001b[36mCompatValidator.__call__\u001b[39m\u001b[34m(self, args, kwargs, fname, max_fname_arg_count, method)\u001b[39m\n\u001b[32m     86\u001b[39m     validate_kwargs(fname, kwargs, \u001b[38;5;28mself\u001b[39m.defaults)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[43mvalidate_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fname_arg_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefaults\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid validation method \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/util/_validators.py:223\u001b[39m, in \u001b[36mvalidate_args_and_kwargs\u001b[39m\u001b[34m(fname, args, kwargs, max_fname_arg_count, compat_args)\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got multiple values for keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m         )\n\u001b[32m    222\u001b[39m kwargs.update(args_dict)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[43mvalidate_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/util/_validators.py:164\u001b[39m, in \u001b[36mvalidate_kwargs\u001b[39m\u001b[34m(fname, kwargs, compat_args)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03mChecks whether parameters passed to the **kwargs argument in a\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03mfunction `fname` are valid parameters as specified in `*compat_args`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \u001b[33;03mmap to the default values specified in `compat_args`\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m kwds = kwargs.copy()\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[43m_check_for_invalid_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m _check_for_default_values(fname, kwds, compat_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Optimization/Project/.venv/lib/python3.12/site-packages/pandas/util/_validators.py:138\u001b[39m, in \u001b[36m_check_for_invalid_keys\u001b[39m\u001b[34m(fname, kwargs, compat_args)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[32m    137\u001b[39m     bad_arg = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(diff))\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: clip() got an unexpected keyword argument 'min'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error\n",
    "\n",
    "# Evaluate other regression models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate additional metrics\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "rf_msle = mean_squared_log_error(y_test.clip(min=0), rf_preds.clip(min=0))\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, lr_preds)\n",
    "lr_msle = mean_squared_log_error(y_test.clip(min=0), lr_preds.clip(min=0))\n",
    "\n",
    "{\n",
    "    \"Random Forest MAE\": rf_mae,\n",
    "    # \"Random Forest MSLE\": rf_msle,\n",
    "    \"Linear Regression MAE\": lr_mae,\n",
    "    # \"Linear Regression MSLE\": lr_msle\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ece189e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest MAE': 8.268333333333334,\n",
       " 'Random Forest MSE': 117.10195000000002,\n",
       " 'Random Forest R2': 0.9294613780871428,\n",
       " 'Random Forest MSLE': 0.8138307097721663,\n",
       " 'Linear Regression MAE': 10.704263769305058,\n",
       " 'Linear Regression MSE': 202.68655945856898,\n",
       " 'Linear Regression R2': 0.8779078351430881,\n",
       " 'Linear Regression MSLE': 0.6722083934833497}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    r2_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the merged dataset again\n",
    "# file_path = \"/mnt/data/merged_weekly_planting_weather.csv\"\n",
    "# merged_df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features and target\n",
    "features = [\"week\", \"prcp_week_in\", \"TMAX\", \"TMIN\", \"TAVG\", \"AWND\"]\n",
    "target = \"pct_planted\"\n",
    "\n",
    "# Drop missing\n",
    "merged_df = merged_df.dropna(subset=features + [target])\n",
    "\n",
    "# Split into train-test\n",
    "X = merged_df[features]\n",
    "y = merged_df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "lr = LinearRegression()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_preds = rf.predict(X_test)\n",
    "lr_preds = lr.predict(X_test)\n",
    "\n",
    "# Ensure no negative predictions for MSLE\n",
    "rf_preds_safe = rf_preds.clip(min=0)\n",
    "lr_preds_safe = lr_preds.clip(min=0)\n",
    "y_test_safe = y_test.clip(lower=0)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Random Forest MAE\": mean_absolute_error(y_test, rf_preds),\n",
    "    \"Random Forest MSE\": mean_squared_error(y_test, rf_preds),\n",
    "    \"Random Forest R2\": r2_score(y_test, rf_preds),\n",
    "    \"Random Forest MSLE\": mean_squared_log_error(y_test_safe, rf_preds_safe),\n",
    "\n",
    "    \"Linear Regression MAE\": mean_absolute_error(y_test, lr_preds),\n",
    "    \"Linear Regression MSE\": mean_squared_error(y_test, lr_preds),\n",
    "    \"Linear Regression R2\": r2_score(y_test, lr_preds),\n",
    "    \"Linear Regression MSLE\": mean_squared_log_error(y_test_safe, lr_preds_safe),\n",
    "}\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c763ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
